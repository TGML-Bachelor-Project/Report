\subsection{Model Evaluation}
\label{sec:Method:Evaluation}
In order to evaluate the modelling performance of the SCVM, the model is evaluated on synthetically generated data. 
This data, which is generated based on chosen parameters $\beta$, $\textbf{Z}$ and $\textbf{V}$, allows for the existence of a ground truth model with metrics which a given trained model should converge towards. 
The utilized datasets are described in section \ref{sec:Data}.
\\
The essence of the model evaluation is verifying that a trained model has modelled a given dynamic network correctly, even though is has not found the true $\textbf{Z}$ and $\textbf{V}$ parameters.
This is important, as there in theory is an infinite set of correct initial parameters, which all correctly model a dynamic network. 


\subsubsection{Beta Convergence}
\label{sec:Method:Evaluation:BetaConvergence}
As stated above, a properly trained SCVM, which correctly models the given synthetically generated dynamic network, most likely does not find the same parameters $\textbf{Z}$ and $\textbf{V}$ as that of the ground truth model.
It should however find a $\beta$ value close to the ground truth, as this parameter strongly governs the intensity of interaction between nodes, as of the intensity function (\ref{eq:IntensityFunc}).
Hence, a strong indication of good modelling performance consists in whether $\beta$ converges correctly.


\subsubsection{Average Training Loss}
\label{sec:Method:Evaluation:Loss}
The loss computed during model training, ie. the negative log likelihood explained in section \ref{sec:Method:LikelihoodFunc}, gives a clear picture of model training progress.
In this project the average loss, meaning the loss over the number of node pairs (dyads) in the given dataset, is used as it represents a more similar metric across different datasets.
The average loss is written as:

\begin{equation}
   \overline{\mathcal{L}} = - \frac{\ell}{n_{dyads}} = - \frac{\sum_{i=1}^n \log \lambda_{u_i,v_i} (t_i) - \sum_{u=1}^{N-1} \sum_{v > u}^{N} \int_{0}^T \lambda_{u,v}(t) \mathrm{d} t}{n_{dyads}}
    \label{eq:LogLikelihoodFuncExplicit}
\end{equation}
When training on synthetic data, the present ground truth model enables for the computation of a ground truth average loss, to which the trained model should preferably converge.


\subsubsection{Intensity Rate Comparison}
\label{sec:Method:Evaluation:Intensity}
The interaction intensity between a given pair of nodes, over the temporal span of the dynamic network, can be inspected accurately and serves as a good, visual comparison to the ground truth model. 
While using the average loss as a metric essentially enables for comparing the altogether deviation between the ground truth model and the learned model, evaluating the intensity plots of single dyads gives a more detailed look into how good a fit the SCVM has produced.


\subsubsection{Node Pair (dyad) Removal}
\label{sec:Method:Evaluation:NodePairRemoval}
Building on top of intensity rate comparison for node pairs, a very concrete test of modelling performance and to some extend modelling stability is devised.
For a given dynamic network consisting of $N$ nodes, with a dataset consisting of $n$ interactions between $\frac{N\cdot(N-1)}{2}$ pairs of nodes, referred to as dyads, this test removes all interactions across time of 10\% of these dyads.
For a dataset consisting of $N = 5$ nodes, node $0,1,2,3,4$, hence with 10 dyads, $(0,1), (0,2), (0,3), (0,4), (1,2) (1,3), (1,4), (2,3), (2,4), (3,4)$, the test removes 1 dyad, say dyad $(0,1)$, and hence all interactions between these two nodes.
After training the SCVM on the data of the remaining nine dyads, the model computes the interaction intensity between dyad $(0,1)$, whose data is unseen.
This computed intensity of interaction is compared with the ground truth for this dyad, thus evaluating how well the model is able to infer the two node's interaction intensity from what it has learned through modelling the seen dyads.


\subsubsection{Accuracy Score of Removed Interactions}
\label{sec:Method:Evaluation:AUC}
In order to test the model both on synthetic and real data, a test which does not require a ground truth is devised.
From a given dataset, 10\% of all interactions are chosen at random as the test set.
The SCVM then trains on the remaining 90\% of interactions in the dataset, learning the best fitting parameters $\beta$, $\textbf{Z}$ and $\textbf{V}$.
\\
For each time point in the test set, i.e. the removed interactions, an alternative, false node pair is randomly sampled.
This results in two sets (lists) of interactions that share the time column; the true test set consisting of the original removed node pair interactions, and the false test set, consisting of randomly sampled alternative node pairs.
For each mutual time point in the true and false test sets, the model computes the probability of interaction between the true node pair and the false node pair.
These probabilities are computed as the log of the event probability, explained under section \ref{sec:Method:Poisson:EventProbability}.
This results in two arrays of event probabilities, a true event probability array and a false probability array.
For each time point, the node pair with the highest event probability is deemed to be the one the trained SCVM believes is the true interaction.
This yields a prediction array with the label corresponding to the predicted node pair for each interaction time point, and with the corresponding true labels a prediction accuracy can be computed.
From the predicted labels and true labels, 75\% are drawn at random, and the accuracy is computed for these.
This is done 10,000 times as to bootstrap the accuracy, yielding a 95\% confidence interval with which the results are evaluated.