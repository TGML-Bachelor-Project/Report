\subsection{Model Evaluation}
\label{sec:Method:Evaluation}
In order to evaluate the performance of the models presented in this project, hence verifying they work as intended, they are evaluated on synthetically generated data. 
This data, which is generated based on chosen parameters $\beta$, $z0$ and $v0$ allows for the existence of a ground truth model with metrics which a given trained model should converge towards. 

The essence of the model evaluation is verifying that a trained model has modelled a given TDGN correctly, even though is has not found the same $z0$ and $v0$ as the synthetic dataset is generated from.
This is important, as there in theory is an infinite set of correct initial parameters, which yield a correctly modelled TDGN. 
Intuitively, initial parameters (\ref{eq:InitParam1}) and (\ref{eq:InitParam2}) below will yield (almost) identical datasets.

\begin{align}
    z0 &= \left( \begin{matrix}
                0.0 & 1.0\\
                0.0 & -1.0\\
                \end{matrix}\right), \hspace{10}
    v0 = \left( \begin{matrix}
                0.0 & -0.01\\
                0.0 & 0.01\\
                \end{matrix}\right), \hspace{10}
    \beta = 7.5
    \label{eq:InitParam1}
    \\
    z0 &= \left( \begin{matrix}
                1.0 & 0.0\\
                -1.0 & 0.0\\
                \end{matrix}\right), \hspace{10}
    v0 = \left( \begin{matrix}
                -0.01 & 0.0\\
                0.01 & 0.0\\
                \end{matrix}\right), \hspace{10}
    \beta = 7.5
    \label{eq:InitParam2}
\end{align}


\subsubsection{Baseline Models}
\label{sec:Method:Evaluation:BaselineModels}
Baseline models will be utilized in order to evaluate wheter the proposed model is an improvement over prior work.

There are three baseline models, which are incrisingly complex in their modelling capability.

The first baseline consists in modelling the data by taking the average intensity of the nodepairs.

The second baseline is the Constant Velocity model withour velocity, ie. merely fitting nodes to the optimal positions, but not attributing them a velocity.

The third baseline used is the one-step Constant Velocity model.
For modelling synthetic dataset 1 which is generated from a single velocity vector, see section \ref{sec:Data:SyntheticData:SyntheticDataset1}, this baseline will be redundant.
For either synthetically generated data on more steps, or real data, this baseline will fit only one velocity for each node, one step.


\subsubsection{Beta Convergence}
\label{sec:Method:Evaluation:BetaConvergence}
A properly trained Constant Velocity Model, which correctly models the given TDGN, most likely does not find the same parameters $z0$ and $v0$ as that of the ground truth model.
It should, however, find a $\beta$-value close to the ground truth, as this parameter strongly governs the intensity of interaction between nodes, as of the intensity function (\ref{eq:IntensityFunc}):
\begin{equation*}
    \lambda_{u,v}(t)
    =
    \exp \left(\beta - ||\textbf{z}_u(t) - \textbf{z}_v(t)||_2^2\right)
\end{equation*}
Hence, a strong indication of good modelling consists in whether $\beta$ converges correctly.


\subsubsection{Average Training Loss}
\label{sec:Method:Evaluation:Loss}
The loss, ie. negative log likelihood computed during model training, see section \ref{sec:Method:LikelihoodFunc}, gives a clear picture of model training progress.
In this project, the average loss, meaning the loss over the number of node pairs (dyads) in the given dataset, is used as it represents a more similar metric across different datasets.
\\
The average loss is written as:

\begin{equation}
   average loss = - \frac{\ell}{n_{dyads}} = - \frac{\sum_{i=1}^n \log \lambda_{u_i,v_i} (t_i) - \sum_{u=1}^{N-1} \sum_{v > u}^{N} \int_{0}^T \lambda_{u,v}(t) \mathrm{d} t}{n_{dyads}}
    \label{eq:LogLikelihoodFuncExplicit}
\end{equation}
When training on synthetic data, the present ground truth model enables for the computation of a ground truth average loss, to which the trained model should preferably converge.


\subsubsection{Intensity Rate Comparison}
\label{sec:Method:Evaluation:Intensity}
The interaction intensity between a given pair of nodes, over the temporal span of the TDGN, can be inspected accurately and serves as a more visual comparison to the GT model than the loss. 
While using the average loss as a metric essentially enables for comparing the altogether deviation between the ground truth model and the learned model, singling out node pairs can better the understanding of a good fit for TDGN's with few nodes.




\subsubsection{Node Pair (dyad) Removal}
\label{sec:Method:Evaluation:NodePairRemoval}
Building on top of intensity rate comparison for node pairs, a very concrete test of modelling performance and to some extend modelling stability is devised.
For a given dynamic network consisting of $N$ nodes, with a dataset consisting of $n$ interactions between $\frac{N\cdot(N-1)}{2}$ pairs of nodes, referred to as dyads, the test removes all interactions of (around) 10\% of these dyads.
For a dataset consisting of $N = 5$ nodes, node $0,1,2,3,4$, hence with 10 dyads, $(0,1), (0,2), (0,3), (0,4), (1,2) (1,3), (1,4), (2,3), (2,4), (3,4)$, the test removes 1 dyad, it could be dyad (0,1), and all interactions between these two nodes.

After training the SCVM on the data of the remaining nine dyads, the model computes the interaction intensity between dyad $(0,1)$, whose data is unseen.
This computed intensity of interaction is then compared with the ground truth for this dyad, hence evaluating how well the model is able to infer the their interaction intensity from what it has learned on the basis of the data for the seen dyads.


\subsubsection{AUC Score of Removed Interactions}
\label{sec:Method:Evaluation:AUC}
In order to test the model on real data, a test which does not require a ground truth is devised.
From a given dataset, 10\% of all interactions are chosen at random as the test set.
The SCVM then trains on the remaining 90\% of interactions in the dataset, learning the best fitting parameter $\beta$, $z0$ and $v0$.

For each time point in the test set, ie. the removed interactions, an alternative, false node pair interaction is randomly sampled.
This results in two sets of interactions; the true test set consisting of the original removed interactions, and the false test set, consisting of randomly sampled interactions between an alternative node pair.
For each mutual time point in the true and false test sets, the model computes the probability of interaction between the rue node pair and the false node pair.
These probabilities are computed as the log of the event probability, explained under section \ref{sec:Method:Poisson:EventProbability}.
This results in two arrays of event probabilities, a true event probability array and a false probability array.

Based on these arrays, the true positive rate and the false positive rate can be computed.
The AUC score is computed as the area under the ROC (Receiver Operating Characteristics) curve, which utilizes these rates.
The ROC curve is the False Positive rate vs. the True Positive rate at some given decision thresh holds.



